{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy c-extensions failed.\n- Try uninstalling and reinstalling numpy.\n- If you have already done that, then:\n  1. Check that you expected to use Python3.9 from \"C:\\Anaconda3\\python.exe\",\n     and that you have no directories in your PATH or PYTHONPATH that can\n     interfere with the Python and numpy version \"1.18.3\" you're trying to use.\n  2. If (1) looks fine, you can open a new issue at\n     https://github.com/numpy/numpy/issues.  Please include details on:\n     - how you installed Python\n     - how you installed numpy\n     - your operating system\n     - whether or not you have multiple versions of Python installed\n     - if you built from source, your compiler versions and ideally a build log\n\n- If you're working with a numpy git repository, try `git clean -xdf`\n  (removes all files not under version control) and rebuild numpy.\n\nNote: this error has many possible causes, so please don't comment on\nan existing issue about this - open a new one instead.\n\nOriginal error was: No module named 'numpy.core._multiarray_umath'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-008a0051d0e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#  Where \"tree_all.dot\" is the generated text file and \"tree_all.png\" is the desired image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     raise ImportError(\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;34m\"Unable to import required dependencies:\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     )\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy c-extensions failed.\n- Try uninstalling and reinstalling numpy.\n- If you have already done that, then:\n  1. Check that you expected to use Python3.9 from \"C:\\Anaconda3\\python.exe\",\n     and that you have no directories in your PATH or PYTHONPATH that can\n     interfere with the Python and numpy version \"1.18.3\" you're trying to use.\n  2. If (1) looks fine, you can open a new issue at\n     https://github.com/numpy/numpy/issues.  Please include details on:\n     - how you installed Python\n     - how you installed numpy\n     - your operating system\n     - whether or not you have multiple versions of Python installed\n     - if you built from source, your compiler versions and ideally a build log\n\n- If you're working with a numpy git repository, try `git clean -xdf`\n  (removes all files not under version control) and rebuild numpy.\n\nNote: this error has many possible causes, so please don't comment on\nan existing issue about this - open a new one instead.\n\nOriginal error was: No module named 'numpy.core._multiarray_umath'\n"
     ]
    }
   ],
   "source": [
    "# Brian Garten\n",
    "# creating a decision tree with root node: DAMAGE_PROPERTY\n",
    "# to look at what factors affect property damage the most\n",
    "\n",
    "# JUST MISSING ACCURACY\n",
    "\n",
    "# Note: to extract output file, use: dot -Tpng tree_all.dot -o tree_all.png\n",
    "#  Where \"tree_all.dot\" is the generated text file and \"tree_all.png\" is the desired image\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import calendar\n",
    "\n",
    "# the node to be analyzed\n",
    "root_node = 'EVENT_TYPE'\n",
    "# what the depth of the leaf nodes will be\n",
    "maxdepth = 3\n",
    "# percentage of data to use\n",
    "data_percentage = 0.1\n",
    "# file name for the output \".dot\" file\n",
    "output_file = \"tree_all_\"+root_node+\".dot\"\n",
    "\n",
    "# preparing and cleaning data\n",
    "df = pd.read_csv(\"weather-data/StormEvents_details-ftp_v1.0_d2019_c20200416.csv\")\n",
    "df = pd.concat([df, pd.read_csv(\"weather-data/StormEvents_details-ftp_v1.0_d2018_c20200317.csv\")])\n",
    "df = pd.concat([df, pd.read_csv(\"weather-data/StormEvents_details-ftp_v1.0_d2017_c20200121.csv\")])\n",
    "df = pd.concat([df, pd.read_csv(\"weather-data/StormEvents_details-ftp_v1.0_d2016_c20190817.csv\")])\n",
    "df = pd.concat([df, pd.read_csv(\"weather-data/StormEvents_details-ftp_v1.0_d2015_c20191116.csv\")])\n",
    "\n",
    "# dropping columns that do not contain data or only apply to some events\n",
    "# magnitude was dropped because it's hail size for some measurements, and wind speed for others\n",
    "df = df.drop(columns = ['BEGIN_DATE_TIME','END_DATE_TIME','MAGNITUDE','MAGNITUDE_TYPE',\n",
    "                        'FLOOD_CAUSE','CATEGORY','TOR_F_SCALE','TOR_LENGTH','TOR_WIDTH',\n",
    "                        'TOR_OTHER_WFO','TOR_OTHER_CZ_STATE','TOR_OTHER_CZ_FIPS',\n",
    "                        'TOR_OTHER_CZ_NAME','EPISODE_NARRATIVE','EVENT_NARRATIVE','DATA_SOURCE'])\n",
    "\n",
    "# restrict dataframe to a specific event type(s) - currently disabled\n",
    "#dfs=[]\n",
    "#for event in analyze:\n",
    "#    dfs.append(df.drop(df[df.EVENT_TYPE != event].index).reset_index(drop=True))\n",
    "#df = pd.concat(dfs) # comment out this line to see all events\n",
    "    \n",
    "# remove outside the continental US - currently disabled\n",
    "#df = df.drop(df[(df.STATE == 'HAWAII') | (df.STATE == 'ALASKA') | (df.STATE == 'E PACIFIC') | (df.STATE == 'ATLANTIC NORTH') | (df.STATE == 'ATLANTIC SOUTH') | (df.STATE == 'GULF OF MEXICO') | (df.STATE == 'HAWAII WATERS') | (df.STATE == 'PUERTO RICO') | (df.STATE == 'VIRGIN ISLANDS') | (df.STATE == 'AMERICAN SAMOA')].index)\n",
    "\n",
    "# calculate event's distance covered\n",
    "df['DISTANCE'] = ((df[\"BEGIN_LAT\"]-df[\"END_LAT\"])**2 + (df[\"BEGIN_LON\"]-df[\"END_LON\"])**2)**(1/2)\n",
    "\n",
    "# calculate event mid points, and remove the start & end locations (might want to add those back in...?)\n",
    "df[\"MID_LAT\"] = (df[\"BEGIN_LAT\"]+df[\"END_LAT\"]) / 2\n",
    "df[\"MID_LON\"] = (df[\"BEGIN_LON\"]+df[\"END_LON\"]) / 2\n",
    "df = df.drop(columns=[\"BEGIN_LAT\",\"END_LAT\",\"BEGIN_LON\",\"END_LON\"])\n",
    "\n",
    "# remove any rows with missing data, then reset the index\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "df = df.loc[:round(len(df)*data_percentage),:] ### SHRINKS DATA DOWN - TEMPORARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the non-numeric values (i.e. 10.00k) to numeric (10000)\n",
    "def unit_converter(df, *argv):\n",
    "    for column in argv:\n",
    "        for i in range(len(df)):\n",
    "            num = df.loc[i,column][:-1] # grab the number\n",
    "            suffix = df.loc[i,column][-1] # grab the suffix (ie K, M, etc)\n",
    "            if (suffix == 'K'): # for thousands\n",
    "                num = float(num) * 1e3\n",
    "            elif (suffix == 'M'): # for millions\n",
    "                num = float(num) * 1e6\n",
    "            elif (suffix == 'B'): # for billions\n",
    "                num = float(num) * 1e9\n",
    "            elif (suffix == 'T'): # for trillions - not sure if this is necessary, billions is though\n",
    "                num = float(num) * 1e12\n",
    "            else:\n",
    "                raise ValueError(num,suffix)\n",
    "            df.loc[i,column] = num\n",
    "    return df\n",
    "\n",
    "df = unit_converter(df,'DAMAGE_PROPERTY','DAMAGE_CROPS')\n",
    "\n",
    "# convert months to numerical representation (Jan = 1, Feb = 2, etc.)\n",
    "mo_to_num = {name: num for num, name in enumerate(calendar.month_name) if num}\n",
    "for i in range(len(df)):\n",
    "    df.loc[i,'MONTH_NAME'] = mo_to_num[df.loc[i,'MONTH_NAME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this in linux console to allow to run: sudo sh -c \"echo 1 > /proc/sys/vm/overcommit_memory\"\n",
    "\n",
    "# separate the root from the decision 'leaves'\n",
    "X = df.drop(columns=root_node)\n",
    "y = df[root_node]\n",
    "\n",
    "# create the categorical data\n",
    "X = pd.get_dummies(X,sparse=True)\n",
    "y = pd.get_dummies(y)\n",
    "# create the decision tree\n",
    "clf = tree.DecisionTreeClassifier(max_depth=maxdepth,random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tree visual w/o values\n",
    "dotstr = tree.export_graphviz(clf, feature_names=X.columns)\n",
    "\n",
    "# remove the long list of values in the visual\n",
    "dotstr = dotstr.split('\\\\nvalue')\n",
    "string = dotstr[0]\n",
    "for i in range(1,len(dotstr)):\n",
    "    section = dotstr[i].split('\"')\n",
    "    string = string + '\"' + '\"'.join(section[1:])\n",
    "file = open(\"Tree Visuals/\"+output_file, \"w\")\n",
    "file.write(string)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tree visual w/ values\n",
    "outfile = open(\"Tree Visuals/\"+output_file, \"w\")\n",
    "dotstr = tree.export_graphviz(clf, out_file=outfile, feature_names=X.columns)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
