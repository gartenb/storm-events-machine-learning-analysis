{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brian Garten\n",
    "# creating a decision tree with root node: DAMAGE_PROPERTY\n",
    "# to look at what factors affect property damage the most from\n",
    "# solely numeric values\n",
    "\n",
    "# JUST MISSING ACCURACY\n",
    "\n",
    "# Note: to extract output file, use: dot -Tpng tree_numeric.dot -o tree_numeric.png\n",
    "#  Where \"tree_numeric.dot\" is the generated text file and \"tree_numeric.png\" is the desired image\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import calendar\n",
    "\n",
    "# the node to be analyzed\n",
    "root_node = 'EVENT_TYPE'\n",
    "# what the depth of the leaf nodes will be\n",
    "maxdepth = 2\n",
    "# file name for the output \".dot\" file\n",
    "output_file = \"tree_all_\"+root_node+\".dot\"\n",
    "\n",
    "\n",
    "# preparing and cleaning data\n",
    "# select all the strictly numeric values to use\n",
    "col_lst = [\"BEGIN_DAY\",\"BEGIN_TIME\",\"END_DAY\",\"END_TIME\",\"STATE_FIPS\",\"MONTH_NAME\",\n",
    "           \"CZ_FIPS\",\"INJURIES_DIRECT\",\"INJURIES_INDIRECT\",\n",
    "           \"DEATHS_DIRECT\",\"DEATHS_INDIRECT\",\"DAMAGE_PROPERTY\",\"DAMAGE_CROPS\",\n",
    "           \"BEGIN_RANGE\",\"END_RANGE\",\"BEGIN_LAT\",\"BEGIN_LON\",\"END_LAT\",\"END_LON\"] # columns to read in\n",
    "# add the root node if it's not in the columns desired\n",
    "if root_node not in col_lst:\n",
    "    col_lst.append(root_node)\n",
    "df = pd.read_csv(\"weather-data/StormEvents_details-ftp_v1.0_d2019_c20200416.csv\", usecols=col_lst)\n",
    "df = pd.concat([df, pd.read_csv(\"weather-data/StormEvents_details-ftp_v1.0_d2018_c20200317.csv\", usecols=col_lst)])\n",
    "df = pd.concat([df, pd.read_csv(\"weather-data/StormEvents_details-ftp_v1.0_d2017_c20200121.csv\", usecols=col_lst)])\n",
    "df = pd.concat([df, pd.read_csv(\"weather-data/StormEvents_details-ftp_v1.0_d2016_c20190817.csv\", usecols=col_lst)])\n",
    "df = pd.concat([df, pd.read_csv(\"weather-data/StormEvents_details-ftp_v1.0_d2015_c20191116.csv\", usecols=col_lst)])\n",
    "\n",
    "# restrict dataframe to a specific event type(s) - currently disabled\n",
    "#dfs=[]\n",
    "#for event in analyze:\n",
    "#    dfs.append(df.drop(df[df.EVENT_TYPE != event].index).reset_index(drop=True))\n",
    "#df = pd.concat(dfs) # comment out this line to see all events\n",
    "    \n",
    "# remove outside the continental US - currently disabled\n",
    "#df = df.drop(df[(df.STATE == 'HAWAII') | (df.STATE == 'ALASKA') | (df.STATE == 'E PACIFIC') | (df.STATE == 'ATLANTIC NORTH') | (df.STATE == 'ATLANTIC SOUTH') | (df.STATE == 'GULF OF MEXICO') | (df.STATE == 'HAWAII WATERS') | (df.STATE == 'PUERTO RICO') | (df.STATE == 'VIRGIN ISLANDS') | (df.STATE == 'AMERICAN SAMOA')].index)\n",
    "\n",
    "# calculate event's distance covered\n",
    "df['DISTANCE'] = ((df[\"BEGIN_LAT\"]-df[\"END_LAT\"])**2 + (df[\"BEGIN_LON\"]-df[\"END_LON\"])**2)**(1/2)\n",
    "\n",
    "# calculate event mid points, and remove the start & end locations (might want to add those back in...?)\n",
    "df[\"MID_LAT\"] = (df[\"BEGIN_LAT\"]+df[\"END_LAT\"]) / 2\n",
    "df[\"MID_LON\"] = (df[\"BEGIN_LON\"]+df[\"END_LON\"]) / 2\n",
    "df = df.drop(columns=[\"BEGIN_LAT\",\"END_LAT\",\"BEGIN_LON\",\"END_LON\"])\n",
    "\n",
    "# remove any rows with missing data, then reset the index\n",
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the non-numeric values (i.e. 10.00k) to numeric (10000)\n",
    "def unit_converter(df, *argv):\n",
    "    for column in argv:\n",
    "        for i in range(len(df)):\n",
    "            num = df.loc[i,column][:-1] # grab the number\n",
    "            suffix = df.loc[i,column][-1] # grab the suffix (ie K, M, etc)\n",
    "            if (suffix == 'K'): # for thousands\n",
    "                num = float(num) * 1e3\n",
    "            elif (suffix == 'M'): # for millions\n",
    "                num = float(num) * 1e6\n",
    "            elif (suffix == 'B'): # for billions\n",
    "                num = float(num) * 1e9\n",
    "            elif (suffix == 'T'): # for trillions - not sure if this is necessary, billions is though\n",
    "                num = float(num) * 1e12\n",
    "            else:\n",
    "                raise ValueError(num,suffix)\n",
    "            df.loc[i,column] = num\n",
    "    return df\n",
    "\n",
    "df = unit_converter(df,'DAMAGE_PROPERTY','DAMAGE_CROPS')\n",
    "\n",
    "# convert months to numerical representation (Jan = 1, Feb = 2, etc.)\n",
    "mo_to_num = {name: num for num, name in enumerate(calendar.month_name) if num}\n",
    "for i in range(len(df)):\n",
    "    df.loc[i,'MONTH_NAME'] = mo_to_num[df.loc[i,'MONTH_NAME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this in linux console to allow to run: sudo sh -c \"echo 1 > /proc/sys/vm/overcommit_memory\"\n",
    "\n",
    "# separate the root from the decision 'leaves'\n",
    "X = df.drop(columns=root_node)\n",
    "y = df[root_node]\n",
    "\n",
    "y = pd.get_dummies(y)\n",
    "\n",
    "# create the decision tree\n",
    "clf = tree.DecisionTreeClassifier(max_depth=maxdepth,random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tree visual\n",
    "dotstr = tree.export_graphviz(clf, feature_names=X.columns)\n",
    "\n",
    "# remove the long list of values in the visual\n",
    "dotstr = dotstr.split('\\\\nvalue')\n",
    "string = dotstr[0]\n",
    "for i in range(1,len(dotstr)):\n",
    "    section = dotstr[i].split('\"')\n",
    "    string = string + '\"' + '\"'.join(section[1:])\n",
    "file = open(\"Tree Visuals/\"+output_file, \"w\")\n",
    "file.write(string)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tree visual w/ values\n",
    "outfile = open(\"Tree Visuals/\"+output_file, \"w\")\n",
    "dotstr = tree.export_graphviz(clf, out_file=outfile, feature_names=X.columns)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
